{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afdaffe5",
   "metadata": {},
   "source": [
    "# Deploying an STL Monitoring Service for the PT\n",
    "\n",
    "In this notebook, we will deploy an STL monitoring service for the PT using `rtamt`.\n",
    "\n",
    "This service will check whether the controller produced [PT_script-2dof_hybrid_test_bench](../hybrid-test-bench/PT_script-2dof_hybrid_test_bench.ipynb) is working as intended. In particular, it will run periodically, and:\n",
    "1. Queries the time series database InfluxDB to get a batch of data from running the [PT_emulator](../hybrid-test-bench/PT_emulator.ipynb).\n",
    "2. Evaluates an STL property on that specification.\n",
    "3. Pushes the robustness of the specification back into InfluxDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76769875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check pre-requisite scripts are available.\n",
    "\n",
    "import os\n",
    "\n",
    "# Get the current working directory. Should be hybrid-test-bench.\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "assert os.path.basename(current_dir) == 'hybrid-test-bench', 'Current directory is not hybrid-test-bench'\n",
    "\n",
    "# Get the parent directory. Should be the root of the repository\n",
    "parent_dir = current_dir\n",
    "\n",
    "# Check that the various scripts are available.\n",
    "\n",
    "\n",
    "# Do we need to create the controller.py script?\n",
    "\n",
    "\n",
    "path_to_check = os.path.join(parent_dir, 'pt_emulator_service.py')\n",
    "assert os.path.exists(path_to_check), f'{path_to_check} not found. Run the required notebooks in order.'\n",
    "\n",
    "path_to_check = os.path.join(parent_dir, 'start_influxdb_rabbitmq.py')\n",
    "assert os.path.exists(path_to_check), f'{path_to_check} not found. Run the required notebooks in order.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50d5dc2",
   "metadata": {},
   "source": [
    "## Starting the Hybrid Test Bench\n",
    "\n",
    "To run the services we will need to open 3 terminals and run our scripts. Command outputs for all the terminals shouldn't indicate the scripts crashing, in order for this to work.\n",
    "\n",
    "Follow the steps:\n",
    "1. Open a terminal in [hybrid-test-bench](../hybrid-test-bench/) and run: `python start_influxdb_rabbitmq.py`\n",
    "\n",
    "2. Open a terminal in [hybrid-test-bench](../hybrid-test-bench/) and run: `python hybrid_test_bench_data_recorder_influx.py`\n",
    "\n",
    "3. Open a terminal in [hybrid-test-bench](../hybrid-test-bench/) and run: `python pt_emulator_service.py`\n",
    "\n",
    "For now we don't have the contoller.py script - maybe we just add a code block which sends the message for applying the force?\n",
    "\n",
    "4. At this stage you have the PT working, and data being recorded to the time series DB. Check in the DB management page that this is the case.\n",
    "\n",
    "\n",
    "**Insert screenshot of a working InfluxDB dashboard**\n",
    "\n",
    "\n",
    "Now that the system is running, we will deploy the STL monitoring service below, following the same approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889e85b0",
   "metadata": {},
   "source": [
    "## Deploying the Monitor\n",
    "\n",
    "The service below queries a batch of data from the past 1h in InfluxDB, and checks that the temperature drops below the max temperature always within 60 seconds of having exceeded it. This is not always the case, so we expect to see the robustness being negative sometimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb3f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile stl_monitoring_service.py\n",
    "\n",
    "# Configure python path to load the hybrid test bench modules\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import logging.config\n",
    "import time\n",
    "from influxdb_client import InfluxDBClient\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "import rtamt\n",
    "\n",
    "# Get the current working directory. Should be hybrid-test-bench.\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "assert os.path.basename(current_dir) == 'hybrid-test-bench', 'Current directory is not hybrid-test-bench'\n",
    "\n",
    "# Get the parent directory. Should be the root of the repository\n",
    "parent_dir = current_dir\n",
    "\n",
    "# The root of the repo should contain the startup folder. Otherwise something went wrong during the inital setup.\n",
    "assert os.path.exists(os.path.join(parent_dir, 'startup')), 'startup folder not found in the repository root'\n",
    "\n",
    "# The root of the repo should contain the installation folder. Otherwise something went wrong during the inital setup.\n",
    "assert os.path.exists(os.path.join(parent_dir, 'installation')), 'installation folder not found in the repository root'\n",
    "\n",
    "bench_startup_dir = os.path.join(parent_dir, 'startup')\n",
    "\n",
    "assert os.path.exists(bench_startup_dir), 'hybrid-test-bench startup directory not found'\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(bench_startup_dir)\n",
    "\n",
    "from communication.server.rabbitmq import Rabbitmq\n",
    "from communication.shared.protocol import ROUTING_KEY_STATE, ROUTING_KEY_FORCES\n",
    "import pt_model as pt_model\n",
    "\n",
    "class STLMonitoringService:\n",
    "\n",
    "    def __init__(self, rabbitmq_config, influxdb_config):\n",
    "\n",
    "        self._rabbitmq = Rabbitmq(**rabbitmq_config)\n",
    "        \n",
    "        url = influxdb_config['url']\n",
    "        token = influxdb_config['token']\n",
    "        self._org = influxdb_config['org']\n",
    "        self._bucket = influxdb_config['bucket']\n",
    "\n",
    "        self._client = InfluxDBClient(url=url, token=token, org=self._org)\n",
    "\n",
    "        self._l = logging.getLogger(\"PT_STLMonitoringService\")\n",
    "\n",
    "        # Specification\n",
    "        self._spec = rtamt.StlDenseTimeSpecification()\n",
    "        # Declare the variables that will correspond to the above signals.\n",
    "\n",
    "            # Add the variable declarations that we'll use and parse.\n",
    "        \n",
    "        \"\"\" self._spec.declare_var('T', 'float')\n",
    "        self._spec.declare_var('max_T', 'float')\n",
    "        self._spec.spec = 'always((T >= max_T) implies (eventually[0:60](T <= max_T)))'\n",
    "        self._spec.parse() \"\"\"\n",
    "\n",
    "    def setup(self):\n",
    "        self._rabbitmq.connect_to_server()\n",
    "\n",
    "        # Initialize the Query API\n",
    "        self._query_api = self._client.query_api()\n",
    "        self._write_api = self._client.write_api(write_options=SYNCHRONOUS)\n",
    "\n",
    "        # Subscribe to any message coming from the Hybrid Test Bench physical twin.\n",
    "        self._rabbitmq.subscribe(routing_key=ROUTING_KEY_STATE,\n",
    "                                on_message_callback=self.process_state_sample)\n",
    "\n",
    "        self._l.info(f\"PT_STLMonitoringService setup complete.\")\n",
    "\n",
    "    def query_influxdb(self):\n",
    "        # Define your Flux query: Query the relevant temperature data.\n",
    "        # Feel free to adjust the start time, but leave the stop time as is.\n",
    "        # We set a stop time of -3s to ensure that the data is aligned from the different measurements.\n",
    "\n",
    "\n",
    "        # In our case it won't be average and max temperatures but forces and displacements. Add that to the query.\n",
    "\n",
    "\n",
    "        \"\"\" flux_query = f'''\n",
    "            from(bucket: \"{self._bucket}\")\n",
    "            |> range(start: -1h, stop: -3s)\n",
    "            |> filter(fn: (r) => r[\"_measurement\"] == \"emulator\" or r[\"_measurement\"] == \"dtcourse_controller\")\n",
    "            |> filter(fn: (r) => r[\"_field\"] == \"average_temperature\" or r[\"_field\"] == \"max_temperature\" or r[\"_field\"] == \"min_temperature\")\n",
    "            |> filter(fn: (r) => r[\"source\"] == \"emulator\" or r[\"source\"] == \"dtcourse_controller\")\n",
    "            |> aggregateWindow(every: 3s, fn: last, createEmpty: true)\n",
    "            |> yield(name: \"last\")\n",
    "        '''\n",
    "        # Execute the query\n",
    "        result = self._query_api.query(org=self._org, query=flux_query)\n",
    "\n",
    "        # From the query above, the data comes in 3 tables (one per measurement).\n",
    "        # Importantly, the data is aligned on the time axis, so we should be able to just transfer the data to the right arrays for ramt.\n",
    "        max_temperature = []\n",
    "        temperature = []\n",
    "    \n",
    "        for table in result:\n",
    "            self._l.debug(\"Table:\")\n",
    "            self._l.debug(table)\n",
    "            for record in table.records:\n",
    "                ts = record.get_time().timestamp()\n",
    "                self._l.debug(\"Record at timestamp: \" + str(ts))\n",
    "                self._l.debug(record)\n",
    "                if record.get_field() == 'max_temperature':\n",
    "                    max_temperature.append([ts, record.get_value()])\n",
    "                elif record.get_field() == 'average_temperature':\n",
    "                    temperature.append([ts, record.get_value()])\n",
    "        \n",
    "        assert len(max_temperature) == len(temperature), 'Temperature and max_temperature data not aligned.'\n",
    "\n",
    "        return temperature, max_temperature \"\"\"\n",
    "\n",
    "    def compute_robustness(self, temperature, max_temperature):\n",
    "        # Evaluate ramt on the signals and get the robustness.\n",
    "        print(\"Evaluating ramt on the signals.\")\n",
    "\n",
    "\n",
    "        # Again, we will be evaluating robustness for forces and displacements, not temp.\n",
    "\n",
    "            # robustness = self._spec.evaluate(['T', temperature], ['max_T', max_temperature])\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def store_robustness(self, robustness):\n",
    "        # Store the robustness in the InfluxDB. Duplicate records on the same timestamp will just be updated.\n",
    "        records = []\n",
    "        for r in robustness:\n",
    "            ts = int(r[0] * 1e9)\n",
    "\n",
    "            records.append({\n",
    "                \"measurement\": \"robustness\",\n",
    "                \"tags\": {\n",
    "                    \"source\": \"stl_monitor\"\n",
    "                },\n",
    "                \"time\": ts,\n",
    "                \"fields\": {\n",
    "                    \"robustness\": r[1]\n",
    "                }\n",
    "                })\n",
    "\n",
    "        self._write_api.write(bucket=self._bucket, record=records)\n",
    "\n",
    "    def process_state_sample(self, ch, method, properties, body_json):\n",
    "        # Log the values received.\n",
    "        self._l.info(f\"Received state sample: {body_json}\")\n",
    "        \n",
    "\n",
    "        # ...\n",
    "        robustness = 0 # Placeholder for the robustness value.\n",
    "\n",
    "\n",
    "        \"\"\" # Get the temperature history from the influxdb, and process the temperature data into signals that ramt can understand.\n",
    "        temperature, max_temperature = self.query_influxdb()\n",
    "\n",
    "        self._l.debug(f\"Temperature: {temperature}\")\n",
    "        self._l.debug(f\"Max Temperature: {max_temperature}\")\n",
    "\n",
    "        # Evaluate ramt on the signals and get the robustness.\n",
    "        robustness = self.compute_robustness(temperature, max_temperature) \"\"\"\n",
    "\n",
    "        self._l.debug(f\"Robustness: {robustness}\")\n",
    "\n",
    "        # Store the robustness in the InfluxDB.\n",
    "        self.store_robustness(robustness)\n",
    "\n",
    "    def start_serving(self):\n",
    "        self._rabbitmq.start_consuming()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get utility functions to config logging and load configuration\n",
    "    from pyhocon import ConfigFactory\n",
    "\n",
    "    # Get logging configuration\n",
    "    log_conf = os.path.join(os.path.dirname(os.getcwd()), 'hybrid-test-bench', 'log.conf')\n",
    "    logging.config.fileConfig(log_conf)\n",
    "\n",
    "    # Get path to the startup.conf file used in the hybrid test bench PT & DT:\n",
    "    startup_conf = os.path.join(os.path.dirname(os.getcwd()), 'hybrid-test-bench', 'software','startup.conf')\n",
    "    assert os.path.exists(startup_conf), 'startup.conf file not found'\n",
    "\n",
    "    # The startup.conf comes from the hybrid test bench repository.\n",
    "    config = ConfigFactory.parse_file(startup_conf)\n",
    "\n",
    "    service = STLMonitoringService(rabbitmq_config=config[\"rabbitmq\"], influxdb_config=config[\"influxdb\"])\n",
    "\n",
    "    service.setup()\n",
    "    \n",
    "    # Start the STLMonitoringService\n",
    "    service.start_serving()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc812dd",
   "metadata": {},
   "source": [
    "Running the above script from a terminal, and then opening the InfluxDB page, should give you the following results:\n",
    "\n",
    "**Insert the two screenshots here once it works - one for data (forces & displacements) and one for robustness**\n",
    "\n",
    "As can be seen, the robustness goes negative ...\n",
    "\n",
    "**And explain the robustness...**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
